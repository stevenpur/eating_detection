{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective**: Exploring methods for building a model for identifying eating activity in Capture24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import scipy.stats as stats\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from joblib import Parallel, delayed\n",
    "import urllib\n",
    "import shutil\n",
    "from tqdm.auto import tqdm\n",
    "import utils  # helper functions -- check out utils.py\n",
    "import zipfile\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.patches as mpatches\n",
    "import tabulate\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import aiden_feature as af\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV, GroupKFold\n",
    "import output_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed files\n",
    "outputpath = os.path.expanduser(\"~/eating_detect/data/\")\n",
    "X = np.load(outputpath + 'processed_data/X.npy', mmap_mode='r')\n",
    "Y = np.load(outputpath + 'processed_data/Y.npy')\n",
    "T = np.load(outputpath + 'processed_data/T.npy')\n",
    "pid = np.load(outputpath + 'processed_data/pid.npy')\n",
    "\n",
    "\n",
    "# extract features\n",
    "# X_feats = pd.DataFrame(Parallel(n_jobs=8)(delayed(af.aidan_features)(x, 100) for x in tqdm(X)))\n",
    "# save extracted features\n",
    "# X_feats.to_pickle(outputpath + 'processed_data/X_feats.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign eating label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the indices of labels that is potentially involved eating\n",
    "eat_indices = np.array([index for index, element in enumerate(Y) if 'eat' in element])\n",
    "\n",
    "# load the dictionary that maps the text labels to simplified labels\n",
    "label_dict_path = os.path.expanduser(\"~/capture24/annotation-label-dictionary.csv\")\n",
    "anno_label_dict = pd.read_csv(\n",
    "    label_dict_path,\n",
    "    index_col='annotation', \n",
    "    dtype='string'\n",
    ")\n",
    "Y_simple = np.array([anno_label_dict.loc[y, 'label:Willetts2018'] for y in Y])\n",
    "\n",
    "# get the unique labels related to eating\n",
    "eating_labels = np.unique(Y[eat_indices])\n",
    "\n",
    "# write the eating labels to a file for manual inspection\n",
    "with open(outputpath + 'eating_labels.txt', 'w') as f:\n",
    "    for item in eating_labels:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "\n",
    "# Now I go the the eating_labels.txt file and manually select the labels that are related to eating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep        118802\n",
      "sit-stand    111261\n",
      "mixed         39398\n",
      "walking       19971\n",
      "vehicle       11580\n",
      "eating         8728\n",
      "bicycling      2990\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# after inspection, I have manually created a dictionary that maps the eating labels to simplified labels\n",
    "eating_label_dict_path = os.path.expanduser(\"~/eating_detect/data/eating_labels_simple.tsv\")\n",
    "eating_label_dict = pd.read_csv(\n",
    "    eating_label_dict_path,\n",
    "    sep='\\t',\n",
    "    dtype='string'\n",
    ")\n",
    "\n",
    "# modify the Y_simple array to add eating-specific labels\n",
    "# only replace with eating and maybe-eating lables, and ignore not-eating labels\n",
    "Y_simple_eating = np.copy(Y_simple).astype('U12')\n",
    "for i in eat_indices:\n",
    "    label = Y[i]\n",
    "    eating_label = eating_label_dict.loc[label, 'simple']\n",
    "    if eating_label == 'eating':\n",
    "        Y_simple_eating[i] = eating_label\n",
    "        \n",
    "# check the frequency of eating lables\n",
    "print(pd.Series(Y_simple_eating).value_counts())\n",
    "\n",
    "# remove records with the maybe-eating labels\n",
    "#rm_ind = np.where(Y_simple_eating == 'maybe-eating')[0]\n",
    "#X_simple_eating = np.delete(X, rm_ind, axis=0)\n",
    "#Y_simple_eating = np.delete(Y_simple_eating, rm_ind, axis=0)\n",
    "#T_simple_eating = np.delete(T, rm_ind, axis=0)\n",
    "#pid_simple_eating = np.delete(pid, rm_ind, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up data for ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (237106, 131)\n",
      "Shape of X_test: (75624, 131)\n"
     ]
    }
   ],
   "source": [
    "# read the features extracted from the accelerometer data\n",
    "X_feats = pd.read_pickle(outputpath + 'processed_data/X_feats.pkl')\n",
    "#X_feats_eating = X_feats.drop(rm_ind, axis=0)\n",
    "\n",
    "# Hold out participants P101-P151 for testing (51 participants)\n",
    "test_ids = [f'P{i}' for i in range(101,152)]\n",
    "mask_test = np.isin(pid, test_ids)\n",
    "mask_train = ~mask_test\n",
    "X_train, Y_train, T_train, pid_train = \\\n",
    "    X_feats[mask_train], Y_simple_eating[mask_train], T[mask_train], pid[mask_train]\n",
    "\n",
    "X_test, Y_test, T_test, pid_test = \\\n",
    "    X_feats[mask_test], Y_simple_eating[mask_test], T[mask_test], pid[mask_test]\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Argument oob_score=True to be used for HMM smoothing (see later below)\n",
    "clf = BalancedRandomForestClassifier(\n",
    "    n_estimators=1000,\n",
    "    replacement=False,\n",
    "    sampling_strategy='not minority',\n",
    "    n_jobs=8,\n",
    "    random_state=42,\n",
    "    verbose=1,\n",
    "    oob_score = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grid Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## searching for the best parameters for max_depth and max_features\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [4, 6, 8, 10],\n",
    "    'max_features': ['sqrt', 0.1, 0.2, 0.3, 0.4, 0.5 ]\n",
    "}\n",
    "group_kfold = GroupKFold(n_splits=2)\n",
    "grid_clf_BA = GridSearchCV(clf, param_grid, cv=group_kfold, scoring='balanced_accuracy')\n",
    "grid_clf_BA.fit(X_train, Y_train, groups=pid_train)\n",
    "Y_test_pred = grid_clf_BA.predict(X_test)\n",
    "\n",
    "# record performance\n",
    "grid_clf_BA_metrics = output_utils.record_performance(grid_clf_eatBA.best_estimator_, Y_test, Y_test_pred, grid_clf.classes_[0])\n",
    "grid_clf_BA_metrics['metrics']\n",
    "\n",
    "# use the best parameters to train the model\n",
    "clf = grid_clf_BA.best_estimator_\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_test_pred = clf.predict(X_test)\n",
    "\n",
    "# record the performance\n",
    "clf_BA_metrics = output_utils.record_performance(clf, Y_test, Y_test_pred, clf.classes_)\n",
    "clf_BA_metrics['metrics']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grid Search - eating BA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## searching for the best parameters for max_depth and max_features\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [4, 6, 8, 10],\n",
    "    'max_features': ['sqrt', 0.1, 0.2, 0.3, 0.4, 0.5 ]\n",
    "}\n",
    "\n",
    "# custom scorer for balance accuracy of only \"eating\"\n",
    "custom_scorer = utils.make_ba_scorer_for_class(\"eating\")\n",
    "\n",
    "# perform the grid search\n",
    "group_kfold = GroupKFold(n_splits=2)\n",
    "grid_clf_eatBA = GridSearchCV(clf, param_grid, scoring=custom_scorer, cv=group_kfold)\n",
    "grid_clf_eatBA.fit(X_train, Y_train, groups=pid_train)\n",
    "Y_test_pred = grid_clf_eatBA.predict(X_test)\n",
    "\n",
    "# record the performance\n",
    "grid_clf_eatBA_metrics = output_utils.record_performance(grid_clf_eatBA.best_estimator_, Y_test, Y_test_pred, grid_clf.classes_[0])\n",
    "grid_clf_eatBA_metrics['metrics']\n",
    "\n",
    "# use the best parameters to train the model\n",
    "clf = grid_clf_eatBA.best_estimator_\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_test_pred = clf.predict(X_test)\n",
    "\n",
    "# record the performance\n",
    "clf_eatBA_metrics = output_utils.record_performance(clf, Y_test, Y_test_pred, clf.classes_)\n",
    "clf_eatBA_metrics['metrics']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Dynamic Time Warping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get the training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msktime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregression\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistance_based\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KNeighborsTimeSeriesRegressor\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# for DTW the feature is the time series itself\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m X_train_dtw \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m[mask_train]\n\u001b[1;32m      5\u001b[0m X_test_dtw \u001b[38;5;241m=\u001b[39m X[mask_test]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sktime.regression.distance_based import KNeighborsTimeSeriesRegressor\n",
    "\n",
    "# for DTW the feature is the time series itself\n",
    "X_train_dtw = X[mask_train]\n",
    "X_test_dtw = X[mask_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Down sample majority classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload utils\n",
    "import importlib\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the target class\n",
    "target_class = 'eating'\n",
    "\n",
    "# get the frequency of each classes in the training set\n",
    "class_freq = pd.Series(Y_train).value_counts()\n",
    "\n",
    "# downsample the classes that have more samples\n",
    "dnsmpl_classes = class_freq[class_freq > class_freq[target_class]].index\n",
    "upsmpl_classes = class_freq[class_freq < class_freq[target_class]].index\n",
    "\n",
    "# downsample the classes to be the same as the target class\n",
    "Y_train_dtw_re_list = []\n",
    "X_train_dtw_re_list = []\n",
    "\n",
    "for cls in dnsmpl_classes:\n",
    "    cls_indices = np.where(Y_train == cls)[0]\n",
    "    y_train_cls = Y_train[cls_indices]\n",
    "    downsampled_indices = utils.resampled_indices(y_train_cls, class_freq[target_class])\n",
    "    y_train_cls_dnsmpl = y_train_cls[downsampled_indices]\n",
    "    X_train_cls_dnsmpl = X_train_dtw[cls_indices[downsampled_indices]]\n",
    "    Y_train_dtw_re_list.append(y_train_cls_dnsmpl)\n",
    "    X_train_dtw_re_list.append(X_train_cls_dnsmpl)\n",
    "\n",
    "for cls in upsmpl_classes:\n",
    "    cls_indices = np.where(Y_train == cls)[0]\n",
    "    y_train_cls = Y_train[cls_indices]\n",
    "    upsampled_indices = utils.resampled_indices(y_train_cls, class_freq[target_class], replace=True)\n",
    "    y_train_cls_upsmpl = y_train_cls[upsampled_indices]\n",
    "    X_train_cls_upsmpl = X_train_dtw[cls_indices[upsampled_indices]]\n",
    "    Y_train_dtw_re_list.append(y_train_cls_upsmpl)\n",
    "    X_train_dtw_re_list.append(X_train_cls_upsmpl)\n",
    "\n",
    "# add the target class\n",
    "cls_indices = np.where(Y_train == target_class)[0]\n",
    "y_train_cls = Y_train[cls_indices]\n",
    "X_train_cls = X_train_dtw[cls_indices]\n",
    "Y_train_dtw_re_list.append(y_train_cls)\n",
    "X_train_dtw_re_list.append(X_train_cls)\n",
    "\n",
    "# Convert the lists to NumPy arrays\n",
    "Y_train_dtw_re = np.concatenate(Y_train_dtw_re_list)\n",
    "X_train_dtw_re = np.vstack(X_train_dtw_re_list)\n",
    "\n",
    "\n",
    "# print frequency of each class\n",
    "print(pd.Series(Y_train_dtw_re).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = KNeighborsTimeSeriesRegressor(algorithm=\"kd_tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m Y_train_coded \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39mtransform(Y_train)\n\u001b[1;32m      6\u001b[0m Y_test_coded \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39mtransform(Y_test)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mregressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_dtw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train_coded\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/eating_detect/lib/python3.11/site-packages/sktime/regression/base.py:223\u001b[0m, in \u001b[0;36mBaseRegressor.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNameError\u001b[39;00m:\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    220\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself.n_jobs must be set if capability:multithreading is True\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    221\u001b[0m         )\n\u001b[0;32m--> 223\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_time_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mround\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m)) \u001b[38;5;241m-\u001b[39m start\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# this should happen last: fitted state is set to True\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/eating_detect/lib/python3.11/site-packages/sktime/regression/distance_based/_time_series_neighbors.py:187\u001b[0m, in \u001b[0;36mKNeighborsTimeSeriesRegressor._fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# store full data as indexed X\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_X \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m--> 187\u001b[0m dist_mat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mknn_estimator_\u001b[38;5;241m.\u001b[39mfit(dist_mat, y)\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/eating_detect/lib/python3.11/site-packages/sktime/regression/distance_based/_time_series_neighbors.py:171\u001b[0m, in \u001b[0;36mKNeighborsTimeSeriesRegressor._distance\u001b[0;34m(self, X, X2)\u001b[0m\n\u001b[1;32m    168\u001b[0m     distance_params \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(distance, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpairwise_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdistance_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m distance(X, X2)\n",
      "File \u001b[0;32m~/miniconda3/envs/eating_detect/lib/python3.11/site-packages/sktime/distances/_distance.py:2146\u001b[0m, in \u001b[0;36mpairwise_distance\u001b[0;34m(x, y, metric, **kwargs)\u001b[0m\n\u001b[1;32m   2144\u001b[0m     y \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m   2145\u001b[0m _y \u001b[38;5;241m=\u001b[39m _make_3d_series(y)\n\u001b[0;32m-> 2146\u001b[0m symmetric \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_equal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2147\u001b[0m _metric_callable \u001b[38;5;241m=\u001b[39m _resolve_metric_to_factory(\n\u001b[1;32m   2148\u001b[0m     metric, _x[\u001b[38;5;241m0\u001b[39m], _y[\u001b[38;5;241m0\u001b[39m], _METRIC_INFOS, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m   2149\u001b[0m )\n\u001b[1;32m   2150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _compute_pairwise_distance(_x, _y, symmetric, _metric_callable)\n",
      "File \u001b[0;32m~/miniconda3/envs/eating_detect/lib/python3.11/site-packages/numpy/core/numeric.py:2439\u001b[0m, in \u001b[0;36marray_equal\u001b[0;34m(a1, a2, equal_nan)\u001b[0m\n\u001b[1;32m   2437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   2438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m equal_nan:\n\u001b[0;32m-> 2439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ma2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mall())\n\u001b[1;32m   2440\u001b[0m \u001b[38;5;66;03m# Handling NaN values if equal_nan is True\u001b[39;00m\n\u001b[1;32m   2441\u001b[0m a1nan, a2nan \u001b[38;5;241m=\u001b[39m isnan(a1), isnan(a2)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# encode the labels to integers\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(Y_train_dtw_re)\n",
    "Y_train_dtw_re_coded = label_encoder.transform(Y_train_dtw_re)\n",
    "Y_test_coded = label_encoder.transform(Y_test)\n",
    "\n",
    "regressor.fit(X_train_dtw_re, Y_train_dtw_re_coded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.fit(X_train_dtw, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform HMM smoothing\n",
    "**Use grid search to find the best HMM emission matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the conveniently provided out-of-bag probability predictions from the\n",
    "# random forest training process.\n",
    "Y_train_prob = clf.oob_decision_function_  # out-of-bag probability predictions\n",
    "labels = clf.classes_  # need this to know the label order of cols of Y_train_prob\n",
    "hmm_params = utils.train_hmm(Y_train_prob, Y_train, labels)  # obtain HMM matrices/params\n",
    "Y_test_pred_hmm = utils.viterbi(Y_test_pred, hmm_params)  # smoothing\n",
    "print('\\nClassifier performance -- HMM smoothing')\n",
    "print('Out of sample:\\n', metrics.classification_report(Y_test, Y_test_pred_hmm))\n",
    "\n",
    "# Check again participant\n",
    "mask = pid_test == 'P101'\n",
    "fig, ax = utils.plot_compare(T_test[mask],\n",
    "                             Y_test[mask],\n",
    "                             Y_test_pred_hmm[mask])\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "#X_resampled, y_resampled = smote.fit_resample(X_train, Y_train)\n",
    "label_encoder = LabelEncoder()\n",
    "y_resampled_encoded = label_encoder.fit_transform(y_resampled)\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "    n_estimators=1000,\n",
    "    use_label_encoder=True,\n",
    "    eval_metric='logloss',  # Added to avoid a warning about the default metric\n",
    "    n_jobs=8,\n",
    "    verbosity=1\n",
    ")\n",
    "xgb_clf.fit(X_resampled, y_resampled_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_encoded = xgb_clf.predict(X_test)\n",
    "Y_test_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(Y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(Y_test, Y_test_pred))\n",
    "\n",
    "# Check again participant\n",
    "mask = pid_test == 'P101'\n",
    "fig, axs = utils.plot_compare(T_test[mask],\n",
    "                              Y_test[mask],\n",
    "                              Y_test_pred[mask])\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    oob_score=True,\n",
    "    n_jobs=8,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "rf_clf.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred = rf_clf.predict(X_test)\n",
    "print('\\nClassifier performance')\n",
    "print('Out of sample:\\n', metrics.classification_report(Y_test, Y_test_pred))\n",
    "\n",
    "# Check again participant\n",
    "mask = pid_test == 'P101'\n",
    "fig, axs = utils.plot_compare(T_test[mask],\n",
    "                              Y_test[mask],\n",
    "                              Y_test_pred[mask])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Argument oob_score=True to be used for HMM smoothing (see later below)\n",
    "clf = BalancedRandomForestClassifier(\n",
    "    n_estimators=1000,\n",
    "    replacement=False,\n",
    "    sampling_strategy='not minority',\n",
    "    n_jobs=8,\n",
    "    random_state=42,\n",
    "    verbose=1,\n",
    ")\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_test_pred = clf.predict(X_test)\n",
    "balanced_accuracy_score(Y_test, Y_test_pred)\n",
    "\n",
    "print('\\nClassifier performance')\n",
    "print('Out of sample:\\n', metrics.classification_report(Y_test, Y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency of each label\n",
    "pd.Series(Y_test_pred).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## searching for the best parameters for max_depth and max_features\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV, GroupKFold\n",
    "\n",
    "custom_scorer = make_ba_scorer_for_class(\"eating\")\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [4, 6, 8, 10],\n",
    "    'max_features': ['sqrt', 0.1, 0.2, 0.3, 0.4, 0.5 ]\n",
    "}\n",
    "\n",
    "\n",
    "group_kfold = GroupKFold(n_splits=2)\n",
    "grid_clf = GridSearchCV(clf, param_grid, scoring=custom_scorer, cv=group_kfold)\n",
    "grid_clf.fit(X_train, Y_train, groups=pid_train)\n",
    "# check best parameters\n",
    "print(grid_clf.best_params_)\n",
    "# max_depth=6\n",
    "\n",
    "# check the performance of all the parameters\n",
    "Y_test_pred = grid_clf.predict(X_test)\n",
    "print('\\nClassifier performance')\n",
    "print('Out of sample:\\n', metrics.classification_report(Y_test, Y_test_pred))\n",
    "\n",
    "# get the balanced accuracy for class 'eating'\n",
    "mask = Y_test == 'eating'\n",
    "# classify Y_test into eating non-eating\n",
    "Y_test_eating = np.copy(Y_test)\n",
    "Y_test_eating[mask] = 'eating'\n",
    "Y_test_eating[~mask] = 'non-eating'\n",
    "# classify Y_test_pred into eating non-eating\n",
    "mask = Y_test_pred == 'eating'\n",
    "Y_test_pred_eating = np.copy(Y_test_pred)\n",
    "Y_test_pred_eating[mask] = 'eating'\n",
    "Y_test_pred_eating[~mask] = 'non-eating'\n",
    "balanced_accuracy_score(Y_test_eating, Y_test_pred_eating)\n",
    "\n",
    "# caluculate the specificty for class 'non-eating'\n",
    "recall_score(Y_test_eating, Y_test_pred_eating, labels=['eating'], average=None)\n",
    "\n",
    "# get the best estimator\n",
    "clf = grid_clf.best_estimator_.set_params(bootstrap=False)\n",
    "clf = grid_clf.best_estimator_.set_params(replacement=False)\n",
    "clf = grid_clf.best_estimator_.set_params(oob_score=True)\n",
    "# fit the best estimator\n",
    "clf.fit(X_train, Y_train)\n",
    "# predict\n",
    "Y_test_pred = clf.predict(X_test)\n",
    "# HMM smoothing\n",
    "# Use the conveniently provided out-of-bag probability predictions from the\n",
    "# random forest training process.\n",
    "Y_train_prob = clf.oob_decision_function_  # out-of-bag probability predictions\n",
    "labels = clf.classes_  # need this to know the label order of cols of Y_train_prob\n",
    "hmm_params = utils.train_hmm(Y_train_prob, Y_train, labels, True)  # obtain HMM matrices/params\n",
    "Y_test_pred_hmm = utils.viterbi(Y_test_pred, hmm_params)  # smoothing\n",
    "print('\\nClassifier performance -- HMM smoothing')\n",
    "print('Out of sample:\\n', metrics.classification_report(Y_test, Y_test_pred_hmm))\n",
    "\n",
    "# detatch and reload utils.py\n",
    "import importlib\n",
    "importlib.reload(utils)\n",
    "\n",
    "\n",
    "\n",
    "# Check again participant\n",
    "mask = pid_test == 'P101'\n",
    "fig, ax = utils.plot_compare(T_test[mask],\n",
    "                             Y_test[mask],\n",
    "                             Y_test_pred_hmm[mask])\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model for later use\n",
    "import pickle\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the balanced accuracy for class 'eating'\n",
    "mask = Y_test == 'eating'\n",
    "# classify Y_test into eating non-eating\n",
    "Y_test_eating = np.copy(Y_test)\n",
    "Y_test_eating[mask] = 'eating'\n",
    "Y_test_eating[~mask] = 'non-eating'\n",
    "# classify Y_test_pred into eating non-eating\n",
    "mask = Y_test_pred_hmm == 'eating'\n",
    "Y_test_pred_eating = np.copy(Y_test_pred_hmm)\n",
    "Y_test_pred_eating[mask] = 'eating'\n",
    "Y_test_pred_eating[~mask] = 'non-eating'\n",
    "balanced_accuracy_score(Y_test_eating, Y_test_pred_eating)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode(alist):\n",
    "    ''' Mode of a list, but return middle element if ambiguous '''\n",
    "    m, c = stats.mode(alist)\n",
    "    m, c = m.item(), c.item()\n",
    "    if c==1:\n",
    "        return alist[len(alist)//2]\n",
    "    return m\n",
    "\n",
    "def rolling_mode(t, y, window_size='100S'):\n",
    "    y_dtype_orig = y.dtype\n",
    "    # Hack to make it work with pandas.Series.rolling()\n",
    "    y = pd.Series(y, index=t, dtype='category')\n",
    "    y_code_smooth = y.cat.codes.rolling(window_size).apply(mode, raw=True).astype('int')\n",
    "    y_smooth = pd.Categorical.from_codes(y_code_smooth, dtype=y.dtype)\n",
    "    y_smooth = np.asarray(y_smooth, dtype=y_dtype_orig)\n",
    "    return y_smooth\n",
    "\n",
    "# Smooth the predictions of each participant\n",
    "Y_test_pred_smooth = []\n",
    "unqP, indP = np.unique(pid_test, return_index=True)\n",
    "unqP = unqP[np.argsort(indP)]  # keep the order or else we'll scramble our arrays\n",
    "for p in unqP:\n",
    "    mask = pid_test == p\n",
    "    Y_test_pred_smooth.append(rolling_mode(T_test[mask], Y_test_pred[mask]))\n",
    "Y_test_pred_smooth = np.concatenate(Y_test_pred_smooth)\n",
    "\n",
    "print('\\nClassifier performance -- mode smoothing')\n",
    "print('Out of sample:\\n', metrics.classification_report(Y_test, Y_test_pred_smooth))\n",
    "\n",
    "# Check again participant\n",
    "mask = pid_test == 'P101'\n",
    "fig, axs = utils.plot_compare(T_test[mask],\n",
    "                              Y_test[mask],\n",
    "                              Y_test_pred_smooth[mask])\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = grid_clf.cv_results_\n",
    "\n",
    "# cv_results is a dictionary where each key is a string and each value is an array.\n",
    "# The keys are metrics and the values are the results for each hyperparameter combination.\n",
    "\n",
    "# For example, to print the mean test score for each parameter combination:\n",
    "for mean_score, params in zip(cv_results['mean_test_score'], cv_results['params']):\n",
    "    print(params, '->', mean_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred = clf.predict(X_test)\n",
    "print('\\nClassifier performance')\n",
    "print('Out of sample:\\n', metrics.classification_report(Y_test, Y_test_pred))\n",
    "\n",
    "# Check again participant\n",
    "mask = pid_test == 'P101'\n",
    "fig, axs = utils.plot_compare(T_test[mask],\n",
    "                              Y_test[mask],\n",
    "                              Y_test_pred[mask])\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_feats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rolling mode smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode(alist):\n",
    "    ''' Mode of a list, but return middle element if ambiguous '''\n",
    "    m, c = stats.mode(alist)\n",
    "    m, c = m.item(), c.item()\n",
    "    if c==1:\n",
    "        return alist[len(alist)//2]\n",
    "    return m\n",
    "\n",
    "def rolling_mode(t, y, window_size='100S'):\n",
    "    y_dtype_orig = y.dtype\n",
    "    # Hack to make it work with pandas.Series.rolling()\n",
    "    y = pd.Series(y, index=t, dtype='category')\n",
    "    y_code_smooth = y.cat.codes.rolling(window_size).apply(mode, raw=True).astype('int')\n",
    "    y_smooth = pd.Categorical.from_codes(y_code_smooth, dtype=y.dtype)\n",
    "    y_smooth = np.asarray(y_smooth, dtype=y_dtype_orig)\n",
    "    return y_smooth\n",
    "\n",
    "# Smooth the predictions of each participant\n",
    "Y_test_pred_smooth = []\n",
    "unqP, indP = np.unique(pid_test, return_index=True)\n",
    "unqP = unqP[np.argsort(indP)]  # keep the order or else we'll scramble our arrays\n",
    "for p in unqP:\n",
    "    mask = pid_test == p\n",
    "    Y_test_pred_smooth.append(rolling_mode(T_test[mask], Y_test_pred[mask]))\n",
    "Y_test_pred_smooth = np.concatenate(Y_test_pred_smooth)\n",
    "\n",
    "print('\\nClassifier performance -- mode smoothing')\n",
    "print('Out of sample:\\n', metrics.classification_report(Y_test, Y_test_pred_smooth))\n",
    "\n",
    "# Check again participant\n",
    "mask = pid_test == 'P101'\n",
    "fig, axs = utils.plot_compare(T_test[mask],\n",
    "                              Y_test[mask],\n",
    "                              Y_test_pred_smooth[mask])\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden Markov Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(utils)\n",
    "# Use the conveniently provided out-of-bag probability predictions from the\n",
    "# random forest training process.\n",
    "Y_train_prob = clf.oob_decision_function_  # out-of-bag probability predictions\n",
    "labels = clf.classes_  # need this to know the label order of cols of Y_train_prob\n",
    "hmm_params = utils.train_hmm(Y_train_prob, Y_train, labels)  # obtain HMM matrices/params\n",
    "Y_test_pred_hmm = utils.viterbi(Y_test_pred, hmm_params)  # smoothing\n",
    "print('\\nClassifier performance -- HMM smoothing')\n",
    "print('Out of sample:\\n', metrics.classification_report(Y_test, Y_test_pred_hmm))\n",
    "\n",
    "# Check again participant\n",
    "mask = pid_test == 'P101'\n",
    "fig, ax = utils.plot_compare(T_test[mask],\n",
    "                             Y_test[mask],\n",
    "                             Y_test_pred_hmm[mask])\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = xgb_clf.predict_proba(X_test)\n",
    "threshold = 0.4  # Example threshold\n",
    "y_pred_adjust = (probabilities[:, 1] >= threshold).astype(int)\n",
    "y_pred_adjust = label_encoder.inverse_transform(y_pred_adjust)\n",
    "print('Out of sample:\\n', metrics.classification_report(Y_test, y_pred_adjust))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_adjust\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
